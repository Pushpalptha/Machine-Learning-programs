{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushpalptha/Machine-Learning-programs/blob/main/MEACHINE_LEARNING_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w34SCmptCck",
        "outputId": "80c77dad-b855-4ec0-a964-3700af04f386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDabDUFYMRaZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJvCBbCry86N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSaG55_nzywj"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/data lab1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NvvSEVF53TLe",
        "outputId": "978aa0a5-87e6-4194-f646-cd33f090f4d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4932504a-aab2-42ea-b400-d66b2778a11f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.no</th>\n",
              "      <th>Name</th>\n",
              "      <th>Roll no</th>\n",
              "      <th>Departement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>k.pushpa</td>\n",
              "      <td>203T1A3101</td>\n",
              "      <td>Cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>latha</td>\n",
              "      <td>203T1A3102</td>\n",
              "      <td>cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>manasa</td>\n",
              "      <td>203T1A3103</td>\n",
              "      <td>cse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>radha</td>\n",
              "      <td>203t1A3104</td>\n",
              "      <td>cse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>rani</td>\n",
              "      <td>203T1A3105</td>\n",
              "      <td>cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>suguna</td>\n",
              "      <td>203T1A3106</td>\n",
              "      <td>cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>vani</td>\n",
              "      <td>203T1A3107</td>\n",
              "      <td>cse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>harika</td>\n",
              "      <td>203T1A3108</td>\n",
              "      <td>cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>priya</td>\n",
              "      <td>203T1A3109</td>\n",
              "      <td>cse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>pravillika</td>\n",
              "      <td>203T1a3110</td>\n",
              "      <td>cse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4932504a-aab2-42ea-b400-d66b2778a11f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4932504a-aab2-42ea-b400-d66b2778a11f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4932504a-aab2-42ea-b400-d66b2778a11f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   S.no        Name     Roll no Departement\n",
              "0     1   k.pushpa   203T1A3101         Cai\n",
              "1     2       latha  203T1A3102         cai\n",
              "2     3      manasa  203T1A3103         cse\n",
              "3     4       radha  203t1A3104         cse\n",
              "4     5        rani  203T1A3105         cai\n",
              "5     6      suguna  203T1A3106         cai\n",
              "6     7        vani  203T1A3107         cse\n",
              "7     8      harika  203T1A3108         cai\n",
              "8     9       priya  203T1A3109         cse\n",
              "9    10  pravillika  203T1a3110         cse"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNOa_IWB3hBk"
      },
      "outputs": [],
      "source": [
        "concept=np.array(data)[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx8FGFxg3zBW",
        "outputId": "9014d226-d7ae-4483-bdc0-2fc3c750b83a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 'k.pushpa ', '203T1A3101'],\n",
              "       [2, 'latha', '203T1A3102'],\n",
              "       [3, 'manasa', '203T1A3103'],\n",
              "       [4, 'radha', '203t1A3104'],\n",
              "       [5, 'rani', '203T1A3105'],\n",
              "       [6, 'suguna', '203T1A3106'],\n",
              "       [7, 'vani', '203T1A3107'],\n",
              "       [8, 'harika', '203T1A3108'],\n",
              "       [9, 'priya', '203T1A3109'],\n",
              "       [10, 'pravillika', '203T1a3110']], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U8f2hOX3-Mc"
      },
      "outputs": [],
      "source": [
        "target=np.array(data)[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFwfKPTY4KjU",
        "outputId": "239c63a4-956d-47ca-ba3c-3255adc2bf03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Cai', 'cai', 'cse', 'cse', 'cai', 'cai', 'cse', 'cai', 'cse',\n",
              "       'cse'], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePwUrZ-T5WHV"
      },
      "outputs": [],
      "source": [
        "def func(concept,target):\n",
        "  for i, val in enumerate(target):\n",
        "    if val==\"yes\":\n",
        "      specific_hypothesis=concept[i].copy()\n",
        "      print(specific_hypothesis)\n",
        "      break\n",
        "    count=0\n",
        "    for i, val in enumerate(concept[i]):\n",
        "      count=count+1\n",
        "      print(\"concept=\",concept[i])\n",
        "      print(\"count=\",count)\n",
        "      if target [i]==\"yes\":\n",
        "        print(\"target[i]=\",target[i])\n",
        "#print (len(specific_hypothesis))\n",
        "        for x in range(len(specific_hypothesis)):\n",
        "          print(\"x=\",x)\n",
        "          if val[x]!=specific_hypothesis[x]:\n",
        "            #print(\"val[x]=\",val[x])\n",
        "            specific_hypothesis[x]='?'\n",
        "            print(\"specific_hypothesis[x]=\",specific_hypothesis)\n",
        "          else:\n",
        "            pass\n",
        "            print(specific_hypothesis)\n",
        "            return specific_hypothesis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NzSP0na-skW",
        "outputId": "72576a1f-3dd3-4b16-d41c-22c6a7559e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "concept= [1 'k.pushpa ' '203T1A3101']\n",
            "count= 1\n",
            "concept= [2 'latha' '203T1A3102']\n",
            "count= 2\n",
            "concept= [3 'manasa' '203T1A3103']\n",
            "count= 3\n",
            "final specific hypothesis None\n"
          ]
        }
      ],
      "source": [
        "print(\"final specific hypothesis\",func(concept,target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIsLCMQ_MUQm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('/content/drive/MyDrive/data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_jZTk0VOb4X"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i63XZkUQPDNY"
      },
      "outputs": [],
      "source": [
        "concepts = np.array(data.iloc[:,0:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVrokhiAQQi_",
        "outputId": "a420f24d-9d77-4887-e4bf-3a0ddb9558f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['sunny', 'warm', 'normal', 'strong', 'warm', 'same'],\n",
              "       ['sunny', 'warm', 'high', 'strong', 'warm', 'same'],\n",
              "       ['rainy', 'cold', 'high', 'strong', 'warm', 'same'],\n",
              "       ['sunny', 'warm', 'high', 'strong', 'warm', 'same']], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concepts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3oKUYA9QU0-"
      },
      "outputs": [],
      "source": [
        "target = np.array(data.iloc[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cqsNZQ3QZO-",
        "outputId": "dfee3e26-f635-4017-cec5-af4bc56009f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['yes', 'yes', 'no', 'yes'], dtype=object)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcdoNeYdQdMW",
        "outputId": "93b82350-6c8b-457d-8595-cba123da8b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialization of specific_h and general_h\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 1\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 2\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 3\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Steps of Candidate Elimination Algorithm 4\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "Final Specific_h:\n",
            "['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
            "\n",
            "Final General_h:\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "def learn(concepts, target):\n",
        "\n",
        "\n",
        "    specific_h = concepts[0].copy()\n",
        "    print(\"\\nInitialization of specific_h and general_h\")\n",
        "    print(specific_h)\n",
        "\n",
        "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
        "    print(general_h)\n",
        "\n",
        "    for i, h in enumerate(concepts):\n",
        "\n",
        "        if target[i] == \"Yes\":\n",
        "            for x in range(len(specific_h)):\n",
        "\n",
        "                if h[x] != specific_h[x]:\n",
        "                    specific_h[x] = '?'\n",
        "                    general_h[x][x] = '?'\n",
        "\n",
        "        if target[i] == \"No\":\n",
        "            for x in range(len(specific_h)):\n",
        "\n",
        "                if h[x] != specific_h[x]:\n",
        "                    general_h[x][x] = specific_h[x]\n",
        "                else:\n",
        "                    general_h[x][x] = '?'\n",
        "        print(\"\\nSteps of Candidate Elimination Algorithm\",i+1)\n",
        "        print(specific_h)\n",
        "        print(general_h)\n",
        "\n",
        "\n",
        "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n",
        "    for i in indices:\n",
        "\n",
        "        general_h.remove(['?', '?', '?', '?', '?', '?'])\n",
        "    return specific_h, general_h\n",
        "s_final, g_final = learn(concepts, target)\n",
        "print(\"\\nFinal Specific_h:\", s_final, sep=\"\\n\")\n",
        "print(\"\\nFinal General_h:\", g_final, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKWc-C2vS1xC"
      },
      "source": [
        "Experiment-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpeRPHm3c6y4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0LuMnwbed7d"
      },
      "outputs": [],
      "source": [
        "df_tennis=pd.read_csv('/content/drive/MyDrive/outlook.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCPKKHxNiSGW",
        "outputId": "1b7b2b01-2c86-4466-8c2a-ff36d448857f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Given Play Tennis Data Set:\n",
            "\n",
            "      out look temperature humidity    wind answer\n",
            "0       sunny         hot     high    weak     no\n",
            "1       sunny         hot     high  strong     no\n",
            "2   over cast         hot     high    weak    yes\n",
            "3        rain        mild     high    weak    yes\n",
            "4        rain        cool   normal    weak    yes\n",
            "5        rain        cool   normal  strong     no\n",
            "6   over cast        cool   normal  strong    yes\n",
            "7       sunny        mild     high    weak     no\n",
            "8       sunny        cool   normal    weak    yes\n",
            "9        rain        mild   normal  strong    yes\n",
            "10      sunny        mild   normal  strong    yes\n",
            "11  over cast        mild     high    weak    yes\n",
            "12  over cast         hot   normal  strong    yes\n",
            "13       rain        mild     high    weak     no\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Given Play Tennis Data Set:\\n\\n\",df_tennis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xehMfWM0iiEX",
        "outputId": "7b4c1861-2fc6-407e-ce16-a528e43c7813"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'out look'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tennis.keys()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7Ek9ss7akzq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDVlEleCiokd"
      },
      "outputs": [],
      "source": [
        "def entropy(probs):\n",
        "    import math\n",
        "    return sum( [-prob*math.log(prob, 2) for prob in probs] )\n",
        "def entropy_of_list(a_list):\n",
        "    from collections import Counter\n",
        "    cnt = Counter(x for x in a_list)\n",
        "    num_instances = len(a_list)*1.0\n",
        "    print(\"\\n Number of Instances of the Current Sub Class is {0}:\".format(num_instances ))\n",
        "    probs = [x / num_instances for x in cnt.values()]\n",
        "    print(\"\\n Classes:\",min(cnt),max(cnt))\n",
        "    print(\" \\n Probabilities of Class {0} is {1}:\".format(min(cnt),min(probs)))\n",
        "    print(\" \\n Probabilities of Class {0} is {1}:\".format(max(cnt),max(probs)))\n",
        "    return entropy(probs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uY1yVONiwAm",
        "outputId": "1c405925-a48f-45ec-84da-925f3243122e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  INPUT DATA SET FOR ENTROPY CALCULATION:\n",
            " 0         sunny\n",
            "1         sunny\n",
            "2     over cast\n",
            "3          rain\n",
            "4          rain\n",
            "5          rain\n",
            "6     over cast\n",
            "7         sunny\n",
            "8         sunny\n",
            "9          rain\n",
            "10        sunny\n",
            "11    over cast\n",
            "12    over cast\n",
            "13         rain\n",
            "Name: out look, dtype: object\n",
            "\n",
            " Number of Instances of the Current Sub Class is 14.0:\n",
            "\n",
            " Classes: over cast sunny\n",
            " \n",
            " Probabilities of Class over cast is 0.2857142857142857:\n",
            " \n",
            " Probabilities of Class sunny is 0.35714285714285715:\n",
            "\n",
            " Total Entropy of PlayTennis Data Set: 1.5774062828523452\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n  INPUT DATA SET FOR ENTROPY CALCULATION:\\n\", df_tennis['out look'])\n",
        "\n",
        "total_entropy = entropy_of_list(df_tennis['out look'])\n",
        "\n",
        "print(\"\\n Total Entropy of PlayTennis Data Set:\",total_entropy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrVu39hOiy79"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from math import exp\n",
        "from random import seed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ranb8dKQM-8F",
        "outputId": "dd65d5d5-ac0d-4527-d33a-35e7c7a1b4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " The input Data Set :\n",
            " [[2.7810836, 2.550537003, 0], [1.465489372, 2.362125076, 0], [3.396561688, 4.400293529, 0], [1.38807019, 1.850220317, 0], [3.06407232, 3.005305973, 0], [7.627531214, 2.759262235, 1], [5.332441248, 2.088626775, 1], [6.922596716, 1.77106367, 1], [8.675418651, -0.242068655, 1], [7.673756466, 3.508563011, 1]]\n",
            "\n",
            " Number of Inputs :\n",
            " 2\n",
            "\n",
            " Number of Outputs :\n",
            " 2\n",
            "\n",
            " The initialised Neural Network:\n",
            "\n",
            "\n",
            " Layer[1] Node[1]:\n",
            " {'weights': [0.4560342718892494, 0.4478274870593494, -0.4434486322731913]}\n",
            "\n",
            " Layer[1] Node[2]:\n",
            " {'weights': [-0.41512800484107837, 0.33549887812944956, 0.2359699890685233]}\n",
            "\n",
            " Layer[2] Node[1]:\n",
            " {'weights': [0.1697304014402209, -0.1918635424108558, 0.10594416567846243]}\n",
            "\n",
            " Layer[2] Node[2]:\n",
            " {'weights': [0.10680173364083789, 0.08120401711200309, -0.3416171297451944]}\n",
            "\n",
            " Network Training Begins:\n",
            "\n",
            ">epoch=0, lrate=0.500, error=5.278\n",
            ">epoch=1, lrate=0.500, error=5.122\n",
            ">epoch=2, lrate=0.500, error=5.006\n",
            ">epoch=3, lrate=0.500, error=4.875\n",
            ">epoch=4, lrate=0.500, error=4.700\n",
            ">epoch=5, lrate=0.500, error=4.466\n",
            ">epoch=6, lrate=0.500, error=4.176\n",
            ">epoch=7, lrate=0.500, error=3.838\n",
            ">epoch=8, lrate=0.500, error=3.469\n",
            ">epoch=9, lrate=0.500, error=3.089\n",
            ">epoch=10, lrate=0.500, error=2.716\n",
            ">epoch=11, lrate=0.500, error=2.367\n",
            ">epoch=12, lrate=0.500, error=2.054\n",
            ">epoch=13, lrate=0.500, error=1.780\n",
            ">epoch=14, lrate=0.500, error=1.546\n",
            ">epoch=15, lrate=0.500, error=1.349\n",
            ">epoch=16, lrate=0.500, error=1.184\n",
            ">epoch=17, lrate=0.500, error=1.045\n",
            ">epoch=18, lrate=0.500, error=0.929\n",
            ">epoch=19, lrate=0.500, error=0.831\n",
            "\n",
            " Network Training Ends:\n",
            "\n",
            "\n",
            " Final Neural Network :\n",
            "\n",
            " Layer[1] Node[1]:\n",
            " {'weights': [0.8642508164347664, -0.8497601716670761, -0.8668929014392035], 'output': 0.9295587965836384, 'delta': 0.005645382825629247}\n",
            "\n",
            " Layer[1] Node[2]:\n",
            " {'weights': [-1.2934302410111027, 1.7109363237151511, 0.7125327507327331], 'output': 0.04760703296164143, 'delta': -0.005928559978815065}\n",
            "\n",
            " Layer[2] Node[1]:\n",
            " {'weights': [-1.3098359335096292, 2.16462207144596, -0.3079052288835877], 'output': 0.1989556395205846, 'delta': -0.03170801648036036}\n",
            "\n",
            " Layer[2] Node[2]:\n",
            " {'weights': [1.5506793402414165, -2.11315950446121, 0.1333585709422027], 'output': 0.8095042653312078, 'delta': 0.029375796661413225}\n"
          ]
        }
      ],
      "source": [
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "    network = list()\n",
        "    hidden_layer = [{'weights':[random.uniform(-0.5,0.5) for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "    network.append(hidden_layer)\n",
        "    output_layer = [{'weights':[random.uniform(-0.5,0.5) for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "    network.append(output_layer)\n",
        "    i= 1\n",
        "    print(\"\\n The initialised Neural Network:\\n\")\n",
        "    for layer in network:\n",
        "        j=1\n",
        "        for sub in layer:\n",
        "            print(\"\\n Layer[%d] Node[%d]:\\n\" %(i,j),sub)\n",
        "            j=j+1\n",
        "        i=i+1\n",
        "    return network\n",
        "def activate(weights, inputs):\n",
        "    activation = weights[-1]\n",
        "    for i in range(len(weights)-1):\n",
        "        activation += weights[i] * inputs[i]\n",
        "    return activation\n",
        "def transfer(activation):\n",
        "    return 1.0 / (1.0 + exp(-activation))\n",
        "def forward_propagate(network, row):\n",
        "    inputs = row\n",
        "    for layer in network:\n",
        "        new_inputs = []\n",
        "        for neuron in layer:\n",
        "            activation = activate(neuron['weights'], inputs)\n",
        "            neuron['output'] = transfer(activation)\n",
        "            new_inputs.append(neuron['output'])\n",
        "        inputs = new_inputs\n",
        "    return inputs\n",
        "def transfer_derivative(output):\n",
        "    return output * (1.0 - output)\n",
        "def backward_propagate_error(network, expected):\n",
        "    for i in reversed(range(len(network))):\n",
        "        layer = network[i]\n",
        "        errors = list()\n",
        "\n",
        "        if i != len(network)-1:\n",
        "            for j in range(len(layer)):\n",
        "                error = 0.0\n",
        "                for neuron in network[i + 1]:\n",
        "                    error += (neuron['weights'][j] * neuron['delta'])\n",
        "                errors.append(error)\n",
        "        else:\n",
        "            for j in range(len(layer)):\n",
        "                neuron = layer[j]\n",
        "                errors.append(expected[j] - neuron['output'])\n",
        "\n",
        "        for j in range(len(layer)):\n",
        "            neuron = layer[j]\n",
        "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "def update_weights(network, row, l_rate):\n",
        "    for i in range(len(network)):\n",
        "        inputs = row[:-1]\n",
        "        if i != 0:\n",
        "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "        for neuron in network[i]:\n",
        "            for j in range(len(inputs)):\n",
        "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\n",
        "    print(\"\\n Network Training Begins:\\n\")\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        sum_error = 0\n",
        "        for row in train:\n",
        "            outputs = forward_propagate(network, row)\n",
        "            expected = [0 for i in range(n_outputs)]\n",
        "            expected[row[-1]] = 1\n",
        "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "            backward_propagate_error(network, expected)\n",
        "            update_weights(network, row, l_rate)\n",
        "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "\n",
        "    print(\"\\n Network Training Ends:\\n\")\n",
        "seed(2)\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "    [1.465489372,2.362125076,0],\n",
        "    [3.396561688,4.400293529,0],\n",
        "    [1.38807019,1.850220317,0],\n",
        "    [3.06407232,3.005305973,0],\n",
        "    [7.627531214,2.759262235,1],\n",
        "    [5.332441248,2.088626775,1],\n",
        "    [6.922596716,1.77106367,1],\n",
        "    [8.675418651,-0.242068655,1],\n",
        "    [7.673756466,3.508563011,1]]\n",
        "\n",
        "print(\"\\n The input Data Set :\\n\",dataset)\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "print(\"\\n Number of Inputs :\\n\",n_inputs)\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "print(\"\\n Number of Outputs :\\n\",n_outputs)\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "print(\"\\n Final Neural Network :\")\n",
        "i= 1\n",
        "for layer in network:\n",
        "    j=1\n",
        "    for sub in layer:\n",
        "        print(\"\\n Layer[%d] Node[%d]:\\n\" %(i,j),sub)\n",
        "        j=j+1\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkLtegjD6v9v"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/data.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1-vFOEBPqgs",
        "outputId": "271309a0-096b-47ed-c4cf-3cb7367076d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-snhVFCsPW1K"
      },
      "source": [
        "def splitDataset(dataset, splitRatio):\n",
        "    trainSize = int(len(dataset) * splitRatio)\n",
        "    trainSet = []\n",
        "    copy = list(dataset)\n",
        "    while len(trainSet) < trainSize:\n",
        "        index = random.randrange(len(copy)) # random index\n",
        "        trainSet.append(copy.pop(index))\n",
        "    return [trainSet, copy]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsoSMUMXDH8C"
      },
      "outputs": [],
      "source": [
        "def separateByClass(dataset):\n",
        "    separated = {}\n",
        "    for i in range(len(dataset)):\n",
        "        vector = dataset[i]\n",
        "        if (vector[-1] not in separated):\n",
        "            separated[vector[-1]] = []\n",
        "        separated[vector[-1]].append(vector)\n",
        "    return separated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4GQMgy1P06K"
      },
      "outputs": [],
      "source": [
        "def mean(numbers):\n",
        "    return sum(numbers)/float(len(numbers))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwnS-Yj0P7rJ"
      },
      "outputs": [],
      "source": [
        "def stdev(numbers):\n",
        "    avg = mean(numbers)\n",
        "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
        "    return math.sqrt(variance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17I2xr6qQBkU"
      },
      "outputs": [],
      "source": [
        "def summarize(dataset):\n",
        "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
        "    del summaries[-1]\n",
        "    return summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2RSY3TQQJY1"
      },
      "outputs": [],
      "source": [
        "def summarizeByClass(dataset):\n",
        "    separated = separateByClass(dataset)\n",
        "    summaries = {}\n",
        "    for classValue, instances in separated.items():\n",
        "        summaries[classValue] = summarize(instances)\n",
        "    return summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08EBFSV9QPBJ"
      },
      "outputs": [],
      "source": [
        "def calculateProbability(x, mean, stdev):\n",
        "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XfsJsXCfRIA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO30RebPQW-O"
      },
      "outputs": [],
      "source": [
        "def predict(summaries, inputVector):\n",
        "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
        "    bestLabel, bestProb = None, -1\n",
        "    for classValue, probability in probabilities.items():\n",
        "        if bestLabel is None or probability > bestProb:\n",
        "            bestProb = probability\n",
        "            bestLabel = classValue\n",
        "    return bestLabel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BcFIoRIQmsJ"
      },
      "outputs": [],
      "source": [
        "def getPredictions(summaries, testSet):\n",
        "    predictions = []\n",
        "    for i in range(len(testSet)):\n",
        "        result = predict(summaries, testSet[i])\n",
        "        predictions.append(result)\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zllt81CQtB_"
      },
      "outputs": [],
      "source": [
        "def getAccuracy(testSet, predictions):\n",
        "    correct = 0\n",
        "    for i in range(len(testSet)):\n",
        "        if testSet[i][-1] == predictions[i]:\n",
        "            correct += 1\n",
        "    return (correct/float(len(testSet))) * 100.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jYYfq5rQyKY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__sgG1QcQ369"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    filename = '/content/drive/MyDrive/5-dataset.csv'\n",
        "    splitRatio = 0.67\n",
        "    dataset = loadcsv(filename)\n",
        "\n",
        "    #print(\"\\n The Data Set :\\n\",dataset)\n",
        "    print(\"\\n The length of the Data Set : \",len(dataset))\n",
        "\n",
        "    print(\"\\n The Data Set Splitting into Training and Testing \\n\")\n",
        "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
        "\n",
        "    print('\\n Number of Rows in Training Set:{0} rows'.format(len(trainingSet)))\n",
        "    print('\\n Number of Rows in Testing Set:{0} rows'.format(len(testSet)))\n",
        "\n",
        "    print(\"\\n First Five Rows of Training Set:\\n\")\n",
        "    for i in range(0,5):\n",
        "        print(trainingSet[i],\"\\n\")\n",
        "\n",
        "    print(\"\\n First Five Rows of Testing Set:\\n\")\n",
        "    for i in range(0,5):\n",
        "        print(testSet[i],\"\\n\")\n",
        "    summaries = summarizeByClass(trainingSet)\n",
        "    print(\"\\n Model Summaries:\\n\",summaries)\n",
        "\n",
        "    predictions = getPredictions(summaries, testSet)\n",
        "    print(\"\\nPredictions:\\n\",predictions)\n",
        "\n",
        "    accuracy = getAccuracy(testSet, predictions)\n",
        "    print('\\n Accuracy: {0}%'.format(accuracy))\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB6Od207hno4",
        "outputId": "7689b6e6-60a5-4fa8-a589-a5fcf12b7bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " The number of categories: 20\n",
            "\n",
            " The 20 Different Categories of 20Newsgroups\n",
            "\n",
            "Category[1]: alt.atheism\n",
            "Category[2]: comp.graphics\n",
            "Category[3]: comp.os.ms-windows.misc\n",
            "Category[4]: comp.sys.ibm.pc.hardware\n",
            "Category[5]: comp.sys.mac.hardware\n",
            "Category[6]: comp.windows.x\n",
            "Category[7]: misc.forsale\n",
            "Category[8]: rec.autos\n",
            "Category[9]: rec.motorcycles\n",
            "Category[10]: rec.sport.baseball\n",
            "Category[11]: rec.sport.hockey\n",
            "Category[12]: sci.crypt\n",
            "Category[13]: sci.electronics\n",
            "Category[14]: sci.med\n",
            "Category[15]: sci.space\n",
            "Category[16]: soc.religion.christian\n",
            "Category[17]: talk.politics.guns\n",
            "Category[18]: talk.politics.mideast\n",
            "Category[19]: talk.politics.misc\n",
            "Category[20]: talk.religion.misc\n",
            "\n",
            " Length of training data is 11314\n",
            "\n",
            " Length of file names is  11314\n",
            "\n",
            " The Content/Data of First File is :\n",
            "\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, ssl\n",
        "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
        "    getattr(ssl, '_create_unverified_context', None)):\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "x = len(twenty_train.target_names)\n",
        "print(\"\\n The number of categories:\",x)\n",
        "print(\"\\n The %d Different Categories of 20Newsgroups\\n\" %x)\n",
        "i=1\n",
        "for cat in twenty_train.target_names:\n",
        "    print(\"Category[%d]:\" %i,cat)\n",
        "    i=i+1\n",
        "print(\"\\n Length of training data is\",len(twenty_train.data))\n",
        "print(\"\\n Length of file names is \",len(twenty_train.filenames))\n",
        "\n",
        "print(\"\\n The Content/Data of First File is :\\n\")\n",
        "\n",
        "print(twenty_train.data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uynfsFqOiZiU",
        "outputId": "c1b1ba36-3b23-4940-8a93-9b3a19960dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "(Target Length , Distinct Words): (11314, 130107)\n",
            "\n",
            " Frequency of the word algorithm: 27366\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "print(\"\\n(Target Length , Distinct Words):\",X_train_counts.shape)\n",
        "print(\"\\n Frequency of the word algorithm:\", count_vect.vocabulary_.get('algorithm'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gka21ygjilql",
        "outputId": "f734969a-c64b-4669-90ba-9a23b53ac352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "X_train_tf.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB461fQLJz2m"
      },
      "outputs": [],
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQbpMlhmSQuv",
        "outputId": "30c952f1-6e93-479a-8b9a-4ce73059942d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.20-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.3.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.21.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pgmpy) (0.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pgmpy) (4.64.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from pgmpy) (3.0.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from pgmpy) (2.8.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.13.0+cu116)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgmpy) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pgmpy) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pgmpy) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pgmpy) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pgmpy) (4.4.0)\n",
            "Installing collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.20\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo2P3fHuiyUr",
        "outputId": "c3a42c17-f08b-40ba-ea67-db57fdec7097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  gender  family  diet  lifestyle  cholestrol  heart diesease\n",
            "0    0       0       1     1          3           0               0\n",
            "1    0       1       1     0          2           1               1\n",
            "2    1       0       0     0          4           1               0\n",
            "3    2       1       0     1          2           0               0\n",
            "4    3       0       1     1          3           1               1\n",
            "5    4       1       0     0          3           0               1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pgmpy/models/BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/dataset.csv\")\n",
        "heart_disease=pd.DataFrame(data)\n",
        "print(heart_disease)\n",
        "from pgmpy.models import BayesianModel\n",
        "model=BayesianModel([\n",
        "('age','Lifestyle'),\n",
        "('Gender','Lifestyle'),\n",
        "('Family','heartdisease'),\n",
        "('diet','cholestrol'),\n",
        "('Lifestyle','diet'),\n",
        "('cholestrol','heartdisease'),\n",
        "('diet','cholestrol')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDQAjc4sI0mP"
      },
      "outputs": [],
      "source": [
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "model.fit(heart_disease, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "from pgmpy.inference import VariableElimination\n",
        "Heart Disease_infer = VariableElimination(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_e3IQfMRIAC"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.datasets import load_iris\n",
        "import sklearn.metrics as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "dataset=load_iris()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku-aGhs9RJmM"
      },
      "outputs": [],
      "source": [
        "X=pd.DataFrame(dataset.data)\n",
        "X.columns=['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
        "y=pd.DataFrame(dataset.target)\n",
        "y.columns=['Targets']\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_zegUgGRaNp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "colormap=np.array(['red','lime','black'])\n",
        "plt.subplot(1,3,1)\n",
        "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y.Targets],s=40)\n",
        "plt.title('Real')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkpuBMj3R1X7"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,3,2)\n",
        "model=KMeans(n_clusters=3)\n",
        "model.fit(X)\n",
        "predY=np.choose(model.labels_,[0,1,2]).astype(np.int64)\n",
        "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[predY],s=40)\n",
        "plt.title('KMeans')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7w7es_URrLF"
      },
      "outputs": [],
      "source": [
        "scaler=preprocessing.StandardScaler()\n",
        "scaler.fit(X)\n",
        "xsa=scaler.transform(X)\n",
        "xs=pd.DataFrame(xsa,columns=X.columns)\n",
        "gmm=GaussianMixture(n_components=3)\n",
        "gmm.fit(xs)\n",
        "y_cluster_gmm=gmm.predict(xs)\n",
        "plt.subplot(1,3,3)\n",
        "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y_cluster_gmm],s=40)\n",
        "plt.title('GMM Classification')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f6SU03ARaK3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris_dataset=load_iris()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p94UWvNX0HS"
      },
      "outputs": [],
      "source": [
        "print(\"\\n IRIS FEATURES \\ TARGET NAMES: \\n \", iris_dataset.target_names)\n",
        "for i in range(len(iris_dataset.target_names)):\n",
        "    print(\"\\n[{0}]:[{1}]\".format(i,iris_dataset.target_names[i]))\n",
        "\n",
        "print(\"\\n IRIS DATA :\\n\",iris_dataset[\"data\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEE_MMx3X4Yd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_dataset[\"data\"], iris_dataset[\"target\"], random_state=0)\n",
        "\n",
        "print(\"\\n Target :\\n\",iris_dataset[\"target\"])\n",
        "print(\"\\n X TRAIN \\n\", X_train)\n",
        "print(\"\\n X TEST \\n\", X_test)\n",
        "print(\"\\n Y TRAIN \\n\", y_train)\n",
        "print(\"\\n Y TEST \\n\", y_test)\n",
        "kn = KNeighborsClassifier(n_neighbors=1)\n",
        "kn.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xX2Fh09DX9Tg",
        "outputId": "2e52de61-b479-4f3c-d226-d3b7419978c6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-74534f90a96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Predicted target value: {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m print(\"\\n Predicted feature name: {}\\n\".format\n\u001b[1;32m      3\u001b[0m     (iris_dataset[\"target_names\"][prediction]))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"\\n Predicted target value: {}\\n\".format(prediction))\n",
        "print(\"\\n Predicted feature name: {}\\n\".format\n",
        "    (iris_dataset[\"target_names\"][prediction]))\n",
        "\n",
        "i=1\n",
        "x= X_test[i]\n",
        "x_new = np.array([x])\n",
        "print(\"\\n XNEW \\n\",x_new)\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test[i]\n",
        "    x_new = np.array([x])\n",
        "    prediction = kn.predict(x_new)\n",
        "    print(\"\\n Actual : {0} {1}, Predicted :{2}{3}\".format(y_test[i],iris_dataset[\"target_names\"][y_test[i]],prediction,iris_dataset[\"target_names\"][prediction]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/heartdisease1.csv\")\n",
        "heartdisease=pd.DataFrame(data)\n",
        "print(heartdisease)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn76cSx2uhAY",
        "outputId": "afd001cb-af0e-466d-83e7-c7031a1354d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    age  gender  family  diet  lifestyle  cholestrol  heartdisease\n",
            "0     0       0       1     1          3           0             1\n",
            "1     0       1       1     1          3           0             1\n",
            "2     1       0       0     0          2           1             1\n",
            "3     4       0       1     1          3           2             0\n",
            "4     3       1       1     0          0           2             0\n",
            "5     2       0       1     1          1           0             1\n",
            "6     4       0       1     0          2           0             1\n",
            "7     0       0       1     1          3           0             1\n",
            "8     3       1       1     0          0           2             0\n",
            "9     1       1       0     0          0           2             1\n",
            "10    4       1       0     1          2           0             1\n",
            "11    4       0       1     1          3           2             0\n",
            "12    2       1       0     0          0           0             0\n",
            "13    2       0       1     1          1           0             1\n",
            "14    3       1       1     0          0           1             0\n",
            "15    0       0       1     0          0           2             1\n",
            "16    1       1       0     1          2           1             1\n",
            "17    3       1       1     1          0           1             0\n",
            "18    4       0       1     1          3           2             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m5WbECxvS_1",
        "outputId": "7b3a2f99-46a7-4571-ea8b-f8b2236caad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.8/dist-packages (0.1.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.3.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from pgmpy) (3.0.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pgmpy) (4.64.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from pgmpy) (2.8.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.13.0+cu116)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pgmpy) (0.12.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pgmpy) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgmpy) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pgmpy) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pgmpy) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pgmpy) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pgmpy) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianModel\n",
        "model=BayesianModel([('age','lifestyle'),('gender','lifestyle'),('family','heartdisease'),('diet','cholestrol'),('lifestyle','diet'),('cholestrol','heartdisease'),('diet','cholestrol')])\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "model.fit(heartdisease,estimator=MaximumLikelihoodEstimator)\n",
        "from pgmpy.inference import VariableElimination\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs60OCnXvKzX",
        "outputId": "2ecb0290-17e9-40e2-be4c-c18fb8b1f77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pgmpy/models/BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heartdisease_infer = VariableElimination(model)\n",
        "print('For age Enter { SuperSeniorCitizen:0, SeniorCitizen:1, MiddleAged:2, Youth:3, Teen:4 }')\n",
        "print('For gender Enter { Male:0, Female:1 }')\n",
        "print('For family history Enter { yes:1, No:0 }')\n",
        "print('For diet Enter { High:0, Medium:1 }')\n",
        "print('For lifestyle Enter { Athlete:0, Active:1, Moderate:2, Sedentary:3 }')\n",
        "print('For cholesterol Enter { High:0, BorderLine:1, Normal:2 }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLtrOhlnvMBl",
        "outputId": "1b9872aa-bbac-4e6e-f205-52c3d8ca03ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For age Enter { SuperSeniorCitizen:0, SeniorCitizen:1, MiddleAged:2, Youth:3, Teen:4 }\n",
            "For gender Enter { Male:0, Female:1 }\n",
            "For family history Enter { yes:1, No:0 }\n",
            "For diet Enter { High:0, Medium:1 }\n",
            "For lifestyle Enter { Athlete:0, Active:1, Moderate:2, Sedentary:3 }\n",
            "For cholesterol Enter { High:0, BorderLine:1, Normal:2 }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = heartdisease_infer.query(variables=['heartdisease'], evidence={'age':int(input('Enter age :')),'gender':int(input('Enter gender :')),'family':int(input('Enter family history :')),'diet':int(input('Enter diet :')),'lifestyle':int(input('Enter lifestyle :')),'cholestrol':int(input('Enter cholestrol :'))})\n",
        "print(q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fycyifvve2n",
        "outputId": "e3b4ca0c-7fe6-4c2e-f404-6a56a575b9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter age :0\n",
            "Enter gender :1\n",
            "Enter family history :1\n",
            "Enter diet :1\n",
            "Enter lifestyle :3\n",
            "Enter cholestrol :0\n",
            "+-----------------+---------------------+\n",
            "| heartdisease    |   phi(heartdisease) |\n",
            "+=================+=====================+\n",
            "| heartdisease(0) |              0.0000 |\n",
            "+-----------------+---------------------+\n",
            "| heartdisease(1) |              1.0000 |\n",
            "+-----------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "i5XHy1afv8kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset=load_iris()\n",
        "print(\"\\n IRIS FEATURES \\ TARGET NAMES: \\n\",iris_dataset.target_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfchcKlU3MAZ",
        "outputId": "c653d820-00e6-4840-9b60-9f4d6069cec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " IRIS FEATURES \\ TARGET NAMES: \n",
            " ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(iris_dataset.target_names)):\n",
        "  print(\"\\n[{0}]:[{1}]\".format(i,iris_dataset.target_names[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY-NmcU03QOJ",
        "outputId": "2fb775a6-91d2-45ef-de9c-5bee06d12c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[0]:[setosa]\n",
            "\n",
            "[1]:[versicolor]\n",
            "\n",
            "[2]:[virginica]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n IRIS DATA :\\n\",iris_dataset[\"data\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AklzsI_o3Tif",
        "outputId": "9001ee7d-8e2b-4c43-ef4e-998082312c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " IRIS DATA :\n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(iris_dataset[\"data\"],iris_dataset[\"target\"],random_state=0)\n",
        "print(\"\\n Target :\\n\",iris_dataset[\"target\"])\n",
        "print(\"\\n X TRAIN \\n\",X_train)\n",
        "print(\"\\n X TEST \\n\",X_test)\n",
        "print(\"\\n Y TRAIN \\n\",y_train)\n",
        "print(\"\\n Y TEST \\n\",y_test)\n",
        "kn=KNeighborsClassifier(n_neighbors=1)\n",
        "kn.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UpZOkww3bZ1",
        "outputId": "f0a105b8-2cde-41ce-b219-0e08a831d6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Target :\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "\n",
            " X TRAIN \n",
            " [[5.9 3.  4.2 1.5]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.6 3.2 1.4 0.2]]\n",
            "\n",
            " X TEST \n",
            " [[5.8 2.8 5.1 2.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.  2.7 5.1 1.6]]\n",
            "\n",
            " Y TRAIN \n",
            " [1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0 1\n",
            " 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0 0\n",
            " 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 1 1 0 0 0 2 1 2\n",
            " 0]\n",
            "\n",
            " Y TEST \n",
            " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
            " 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new=np.array([[5,2.9,1,0.2]])\n",
        "print(\"\\n XNEW \\n\",x_new)\n",
        "prediction=kn.predict(x_new)\n",
        "print(\"\\n Predicted target value:{}\\n\".format(prediction))\n",
        "print(\"\\n Predicted feature name:{}\\n\".format(iris_dataset[\"target_names\"][prediction]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc8IP-ja3h0N",
        "outputId": "5d8db804-5403-4cc5-9fb7-24563cd80123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " XNEW \n",
            " [[5.  2.9 1.  0.2]]\n",
            "\n",
            " Predicted target value:[0]\n",
            "\n",
            "\n",
            " Predicted feature name:['setosa']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "x=X_test[i]\n",
        "x_new=np.array([x])\n",
        "print(\"\\n XNEW \\n\",x_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C4Tt1he3jqR",
        "outputId": "3fce65a2-02bd-43bf-87d7-91ae08a66a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " XNEW \n",
            " [[6.  2.2 4.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_test)):\n",
        "  x=X_test[i]\n",
        "  x_new=np.array([x])\n",
        "  prediction=kn.predict(x_new)\n",
        "  print(\"\\n Actual : {0} {1}, Predicted :{2}{3}\".format(y_test[i],iris_dataset[\"target_names\"][y_test[i]],prediction,iris_dataset[\"target_names\"][prediction]))"
      ],
      "metadata": {
        "id": "wTq-8hsP3sxj",
        "outputId": "3fd1d068-205b-4ec6-a6ba-9a25498c6780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 2 virginica, Predicted :[2]['virginica']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[1]['versicolor']\n",
            "\n",
            " Actual : 0 setosa, Predicted :[0]['setosa']\n",
            "\n",
            " Actual : 1 versicolor, Predicted :[2]['virginica']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rJs_9Rgn36D7hi0zsofmm7guPev07cG3",
      "authorship_tag": "ABX9TyNOD0Xc6soyrEatsoVyL+qw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}